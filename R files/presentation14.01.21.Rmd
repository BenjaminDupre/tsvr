---
title: "Tactile Stimulation in VR"
author: ""
output: 
  flexdashboard::flex_dashboard:
    theme: united

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_knit$set(eval.after = 'fig.cap')
########## Loading Domains
library(merTools)
library(ez) # for anovas
library(ggplot2) # in every graph
library(plyr) # for building the rt graph
library(lme4) # to test difference in accuracy
library(lmerTest) # to test Now approx p-val w/Kenward-Roger’s approximations
library(gridBase) # its used to mixed the graphics together base and ggplot
library(grid) # its used to mixed the graphics together base and ggplot
########## Defining Working Folder
setwd('/Users/calypso/Dropbox/My Mac (glaroam2-185-117.wireless.gla.ac.uk)/Documents/Research MaxPlank/P1_propioception/R_tsvr_presentation/data/')
##########Loading File
tsvr <- read.table('responsetime.csv',header=T,sep = ',',dec = '.') # this is the file saved from the matlab file 
tsvr2 <- read.table('behavioral_a.csv', header=T,sep = ',',dec = '.')
########## Running ANOVA for RT
tsvr$stimulus <- factor(tsvr$stimulus, levels = c(3, 2, 1))
tsvr$stimulus <-revalue(tsvr$stimulus, c("3"="base", "2"="Incongruent", "1"="Congruent"))
tsvr$ptcp <- factor(tsvr$ptcp)
# tsvr$lvl <- factor(tsvr$lvl)
# tsvr$set <- factor(tsvr$set)
data_summary <- function(data, varname, grps){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      sd = sd(x[[col]], na.rm=TRUE))
  }
  data_sum<-ddply(data, grps, .fun=summary_func, varname)
  data_sum <- rename(data_sum, c("mean" = varname))
  return(data_sum)
}

```

1.Experimental Design & Hypothesis {data-navmenu="Content"}
=====================================

Row {data-height=350}
-------------------------------------

#### Hypothesis


Several effects have been found on how heartbeat influences conscious perception. To make sense of these findings, we need to look into effects that seem to occur in opposite directions. Particularly, some findings point towards a heart-evoked activity which is positively related to external perception from the visual domain (Park et al., 2014); whereas from the somatosensory domain, heart-evoked activity has a negative relation with external perception (Esra et al., 2020). 

To account for this, **the previously mentioned paper hypothesized that heart-related processes in the interoceptive cortices may interfere differently during the processing of exteroceptive somatosensory and visual signals (Esra et al., 2020)**. 

**To test this hypothesis**, we have developed a withing subject virtual reality experiment that will simulate visual and haptic stimuli as provided by Virtual Reality Equipment and Software. The measurements use to test the hypothesis are VR behavioral derived and Electro Cardiogram Data (ECG). It is important to hold in mind that this is an exploratory study that will test whether vision-haptic integration can be studied with VR and heart data while performing a complex cognitive task.    

Additional to the experimental set up experiment, there are traditional interoceptive measures such as heartbeat accuracy (Garfinkel et al., 2014), Edinburgh Handedness Questionnaire and a cibersicknes questionnaire. This will allow to nest our results in previous literature. 

#### Task Design:

We device an experiment that was carried out with an HTC VIVE headset and two lighthouses. The haptic feedback was generated over data-gloves from "Neurodigital Technologies". The heart data was collected using Arduino Uno and a SparkFun AD8232 HR  Monitor. All the data is directly relayed into a log file compile by Unity software through USB2 cable with a 133HZ frequency. Leap motion and data-glove positioning where merged together so to increase accuracy in hands and grabbing information.

The first step of the experiment requires for participants to sign the ethical forms, consent forms as well as the handedness and the base cybersickness questionnaire.

Once in the testing room participants are prepared with the ECG equipment. Then they will go through the pre-experiment heartbeat tracking accuracy test (this consist of silent counting of heartbeat in a 1-minute time window). Next, after geting into the VR headsets and datagloves, the calibration process (letters (a) and (b) in figure 1) begin. Finally the VR task begins. Participants are required to memorise the correct position of the red ball among all the empty slots and distracting colours for a period of X seconds and position the ball (letter c and d in figure 1). They need to perform during three blocks of 36 trials to complete the task.

Details: The red ball will be introduced to one of the hands from the top. They will see a template on the table, which is an identical depiction of the sketch they have seen and memorized at the beginning. The participant has to put the ball in the correct location as fast as possible. The withing subject manipulation that the participant is exposed too is given by the haptic feedback. The base condition is when there is no haptic feedback at all. The incongruous condition is when the ball is placed in the opposite hand from where we visually see the balled being placed. The congruent case is when the participant can feel the haptic stimuli in the same hand the ball is placed. 

Finally, there is a post-experiment for heartbeat tracking accuracy (silent counting of heartbeat in specified 1-minute time window) and a final post-cybersickness questionnaire. 

Column {data-height=600}
-------------------------------------
###
```{r imagen, echo= FALSE,out.width="45%", fig.align='bottom',fig.cap = "Task Design: every trail consists of the same four steps. The first two steps are calibration stages. The last two are part of the memory task **A)** Over the table position calibration **B)** Turning the palms for orientation calibration **C)** Fixating the correct red ball position **D)** Placing the red ball on the correct recalled position"}
knitr::include_graphics("design_ilustration.png")
```
2. Data Processing & Methods of Analysis {data-navmenu="Content"}
=====================================
### (re-do ) Data Description

The following dataset used in the analysis counts with a variable number for participants (ptcp), a variable number for the 'set,' which refers to one of the three chunks of uninterrupted trails and a variable called level ('lvl') assigned each of the 36-trials presented per set.

The variable 'start' corresponds to the moment the ball is placed in the hand of the participant. The number represents the row position in the original raw data. Likewise, 'end' corresponds to the explosion of the board and it also represents a row position in the original raw data. 

The variable 'accuracy' takes value 1 when there is a mistake 0 otherwise.

The variable 'diff' refers to the time difference between 'start' and 'end', expressed in seconds and to finalize the categorical variable 'stimulus' signals whether the participant felt the vibration on the same hand the see the ball placed or not.

There are some trails being left out due to participants taking longer than 6 seconds to answer, when placed the ball not being recognized, or if there was a ezPlotdata glove failure.  

```{r tsvr, echo= FALSE}
summary(tsvr)
```
### Methods of Analysis. 

Here comes the methods description. 

3. Preliminary Analysis {data-navmenu="Content"}
=====================================

In total there where 22 people included in the experiment, not counting 5 individuals who perform a pilot version of it. From the 22 persons included the age range goes from 18 to 50 $(M=24.14,SD=6.42)$ normally distributed. There were 17 female participants and 5 male participants. 

#### Behavioral 
The haptic manipulation had ambiguous behavioural results compare to the previously outline hypothesis. In terms of accuracy the difference between stimulus is narrow. The mean accuracy percentage (computed for every participant and then globally) for the base haptic stimuli $94.57\%$, for the incongruent haptic stimuli was $94.99\%$ and for congruent visuo-haptic stimuli it was $94.80\%$ **(is not normal distributed what shoudl i add IC or SD?)** $[F(1,2039)= 0.027, MSE= 0.00, p = 0.974 ,\eta^{2}=0.003]$. This shows that the difficulty of the task was not too high. Also, that when the stimuli ocurred it was not translated into a detriment for accuracy behavior. Is it possible to observe a change on behavior or physiology that could  

Given that the experiment design is factorial and that accuracy variable for every trial is a binary variable –1 if incorrect and 0 if correct– a simple one way-ANOVA analysis will not detect the effects we are interested in fully. In the main analysis section, we run a **(check this) multilevel analysis  or general linear mixed model** predict the accuracy considering as fix effects stimulus, set and level and random effects for participant.

The within participants ANOVA results for Response Time were significant $[F(2,42)= 3.52, SSn= 0.03, p = 0.03^* ,\eta^{2}=0.003]$. The response time range for base stimuli was between 3.12s to 6.00s $(M=3.75 s, SD=0.64)$, for incongruent visuo-haptic stimuli was from 3.12 to 5.97 $(M=3.72s, SD=0.63)$ and for the congruent visuo-haptic stimuli it was from 3.13 to 5.96 $(M=3.69s, SD=0.62)$  . 

```{r, include=FALSE}
# Global mean
data_summary(tsvr, varname="diff", grps = "stimulus")
data_summary(tsvr, varname="accuracy", grps = "stimulus")
# Within Ss ANOVA 
output_anova = ezANOVA(data = tsvr,
        dv = .(diff),
        wid = .(ptcp),
        within = .(stimulus),
        within_covariates = set,
        detailed = T)
print(output_anova)
# Improve this Chi square test for accuracy it has problems - non-normal residual
chisq <- chisq.test(table(tsvr$stimulus,tsvr$accuracy))
```
#### Questionaires

After the VR experience participants on average reported lower heart rate count for the post VR $(M=49.25,SD=20.04)$ case than the pre VR case $(M=57.28, SD=19.45)$. The difference is significant while running an ANOVA. 
```{r, include=FALSE }
setwd("/Users/calypso/Dropbox/My Mac (glaroam2-185-117.wireless.gla.ac.uk)/Documents/Research MaxPlank/P1_propioception/R_tsvr_presentation/data")
# Loading csv file 
meta <- read.csv('meta-data.csv',header=T,sep = ',',dec = '.',fill = TRUE, na.strings=c(""," ","NA"), stringsAsFactors=FALSE) # this is the file sheet as from the drive.
meta <- meta[-23,c(-7,-10,-11)]
meta$post <- as.integer(meta$post) # correcting post consider as chr
```
```{r, echo=TRUE }
a<- aov(meta[,8]  ~ meta[,7])
summary(a)  

```

4. Main Results {data-navmenu="Content"}
=====================================
Row
-------------------------------------
### **Multi-level Model**

We fitted a multi-level model that explained response time (diff) (This were the results found significant in the previous preliminary analysis). On this model we have as fixed effects: trial level, set number and stimulus conditionS. As random effects we are considering the participant (ptcp) variable. The formulation would look something like this: $$diff = 1+stimulus+lvl+set+(1|ptcp)$$. 

The results from the randome effects show that 16% of the variance in time response is accounted by the difference in participants. The estimator most prominent on impact size is found for level variable $[M=-0.20, Pr<0.001, 97.5\%, CI = [-0.22, -0.17]]$. The second most relevant was the congruent visuo-haptic stimulus $[M=-0.20, Pr<0.001, 97.5\%, CI = [-0.22, -0.17]]$. There were no significant results found for the incongruent visuo-haptic stimulus.

***From a Behavior stand point, the coherence of the viuso-haptic stimuli notably makes the reaction faster. Nonetheless, the fact that there is not a significant result for the incongruent visuo-haptic stimuli might cast some light on the multisensory integration of ambiguous sources. As observed in the preliminary results section, the significant difference is between no visuo-haptic stimuli and congruent visuo-haptic stimuli. The incongruent case sits between this two. As an intermediate case, where none is the slowest  and congruent is the fastest** 

```{r, echoe=TRUE}
################### Randome Intercept Model for Response Time 
rndintercepmodel <- lmer(diff~1+(1|ptcp),REML = F,tsvr)
summary(rndintercepmodel)
confint(rndintercepmodel)

# Calculating ICC 
ICC(outcom="diff", group="ptcp", data=tsvr)

# adding 1 level predictors   
rndintercepmodel1 <- lmer(diff~1+lvl+set+(1|ptcp),REML = F,tsvr)
summary(rndintercepmodel1)
confint(rndintercepmodel1)

# adding 1 level predictors final  
rndintercepmodel2 <- lmer(diff~1+stimulus+lvl+set+(1|ptcp),REML = F,tsvr)
summary(rndintercepmodel2)
confint(rndintercepmodel2)

# compmaring models
anova(rndintercepmodel,rndintercepmodel1,rndintercepmodel2)

```



5. Heart data to include in main results section {data-navmenu="Content"}
=====================================
### **Testing for IBI difference between conditions withing subjects (base, congruent, incongruent).**
 try a different calculation using circular statistics. 
 
```{r, include=FALSE}
setwd('/Users/calypso/Dropbox/My Mac (glaroam2-185-117.wireless.gla.ac.uk)/Documents/Research MaxPlank/P1_propioception/R_tsvr_presentation/data/')
tsvr2 <- read.table('behavioral_a.csv', header=T,sep = ',',dec = '.')
tsvr2 <- tsvr2[!(tsvr2$ptcp== 2 |tsvr2$ptcp== 3 | tsvr2$ptcp == 13 | tsvr2$ptcp == 11),]
tsvr2$stimulus <- factor(tsvr2$stimulus, levels = c(3, 2, 1))
tsvr2$stimulus <-revalue(tsvr2$stimulus, c("3"="base", "2"="Incongruent", "1"="Congruent"))
tsvr2<- na.omit(tsvr2)
```

a.- Inter beat intervals where detected using Hooman Sedghamiz (2018) algorithm. I consider the two seconds after the vibrations starts. The analysis was run without getting into detail of artifact removal.The removal of IBI where done using  ‘rmoutliers’ MATLAB function. 

At this point there were no significant difference between beat intervals.

```{r, echo=TRUE, warning=FALSE, fig.align = "center"}
output_anova2 = ezANOVA(data = tsvr2,
                       dv = IBI,
                       wid = ptcp,
                       within = .(stimulus),
                       within_covariates = .(set),
                       detailed = T)
print(output_anova2)
```

### Graphic

```{r, echo=FALSE, warning=FALSE, fig.align = "center"}
ibig <- ezPlot(data = tsvr2,
               dv = IBI,
               wid = ptcp,
               within = .(stimulus),
               within_covariates = .(set),
               x = .(stimulus))
ibig = ibig +  labs(title ="IBI per Condition", x = "Visual - Heptic Stimuli", y = "(mean in seconds)") + 
  theme(
    panel.grid.major.y = element_line(colour = "gray80", size = NULL, linetype = NULL,  
                                      lineend = NULL)
    ,panel.grid.minor.y = element_line(colour = "gray90", size = NULL, linetype = NULL,
                                       lineend = NULL)
    ,panel.grid.major.x = element_blank()           
    ,panel.grid.minor.x = element_blank()
    ,legend.background = element_rect(fill = NULL, colour = "black") 
    
    ,panel.background = element_rect(fill = "white", colour = "white", size = NULL, 
                                     linetype = NULL)
  )
ibig
```



5. Interpretation {data-navmenu="Content"}
=====================================
### **Results Enumeration (must be edited)**

a. Most of the differences in time response are explained by individual differences. 

b. There is for all participants a decrease in time responses as they play more showed by level and set influence. This is also observed in accuracy, although because is not significant it will not be included (?). The improvement of participants throughout the time played indicates learning.  

c. Once removed from the effects we had just mentioned we can now look into the variable of our interest. How do people react to congruent incongruent visuo-haptic stimuli on VR? Our results indicate that the congruence in both senses leads to improvement in performance. Counter to our intuition the incongruent case would still be better in performance than the only one visual case or base case (although this results can only be observed, are not significant the difference is too small.)  

d. There where no significant differences found on R-peak distances. 

e. After the VR experience participants on average reported lower heart rate count for the post VR $(M=49.25,SD=20.04)$ case than the pre VR case $(M=57.28, SD=19.45)$  




<style>

#sidebar.section.sidebar {

  background-color: white; 
  font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif !important;

}

.js-irs-0 .irs-bar {
border-top-color: #d01010;
border-bottom-color: #d01010;
} 

.js-irs-0 .irs-bar-edge {
border-color: #d01010;
}

.js-irs-0 .irs-single, .js-irs-0 .irs-bar-edge, .js-irs-0 .irs-bar {
background: #a00;
}

</style>






